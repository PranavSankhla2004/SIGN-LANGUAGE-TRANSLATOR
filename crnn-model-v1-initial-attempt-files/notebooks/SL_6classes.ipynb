{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SL_6classes.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9eehiN64fxol"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGeypECmM0JT"
      },
      "source": [
        "! pip install mediapipe\n",
        "! pip install sk-video\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import skvideo.io\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2 \n",
        "import mediapipe as mp\n",
        "import skvideo.io\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhO7n8Lf6cQz",
        "outputId": "02c338a8-3c1b-4ac0-9c8c-07677bda660c"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat May  1 12:32:12 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPyx5UH4NCIB"
      },
      "source": [
        "! wget https://zenodo.org/record/4010759/files/Days_and_Time_3of3.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwR1ch9zNQPN"
      },
      "source": [
        "! unzip Days_and_Time_3of3.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3GbXOkVNosk"
      },
      "source": [
        "mp_drawing=mp.solutions.drawing_utils\n",
        "mp_holistic=mp.solutions.holistic\n",
        "\n",
        "def pose_estimation(image,results):\n",
        "        \n",
        "        # 1. Draw face landmarks\n",
        "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS, \n",
        "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
        "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
        "                                 )\n",
        "        \n",
        "        # 2. Right hand\n",
        "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
        "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
        "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
        "                                 )\n",
        "\n",
        "        # 3. Left Hand\n",
        "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
        "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
        "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
        "                                 )\n",
        "\n",
        "        # 4. Pose Detections\n",
        "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
        "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
        "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
        "                                 )\n",
        "                        \n",
        "        return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJgByBFXNrva"
      },
      "source": [
        "for dirpath,dirname,file in os.walk(\"./Days_and_Time\"):\n",
        "   for i in dirname:\n",
        "    os.makedirs(os.path.join(\"./Output/\",i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnE8kQDZNtgL"
      },
      "source": [
        "def video_array_maker(pather,height=224,width=224):\n",
        "  videodata = skvideo.io.vread(pather)  \n",
        "  outpath=os.path.join(\"./Output\",pather.split(\"/\")[2],os.path.split(pather)[1])\n",
        "  out = cv2.VideoWriter(outpath,cv2.VideoWriter_fourcc('M','J','P','G'), 10, (width,height))\n",
        "  #start=time.time()\n",
        "\n",
        "  with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
        "#    arr=[]\n",
        "    actualframe=len(videodata)\n",
        "    print(\"Actual frame {}\".format(actualframe))\n",
        "    if actualframe >=45:\n",
        "          for i in range (actualframe):\n",
        "            x=round (actualframe/(45)  * i)\n",
        "            if x >=actualframe:\n",
        "                    break\n",
        "            else:\n",
        "                frame =videodata[x]\n",
        "                frame =cv2.resize(frame,(width,height),interpolation=cv2.INTER_AREA)\n",
        "                results = holistic.process(frame)  \n",
        "\n",
        "                output = pose_estimation(frame,results)\n",
        "                output =cv2.cvtColor(output,cv2.COLOR_BGR2RGB)\n",
        "#                arr.append(output)\n",
        "                out.write(output)               \n",
        "    else:\n",
        "          for i in range(actualframe):\n",
        "              frame=videodata[i]\n",
        "              frame=cv2.resize(frame,(width,height),interpolation=cv2.INTER_AREA)\n",
        "              results = holistic.process(frame)  \n",
        "              output = pose_estimation(frame,results)\n",
        "              output =cv2.cvtColor(output,cv2.COLOR_BGR2RGB)\n",
        " #             arr.append(output)\n",
        "              out.write(output)\n",
        "          for i in range(45-actualframe):\n",
        "              \n",
        "              newframe=np.zeros(shape=(height,width,3))\n",
        "              \n",
        "#              arr.append(newframe)\n",
        "              out.write(np.uint8(newframe))\n",
        "    out.release()\n",
        "    print(\"File Created : {}\".format(outpath))\n",
        "    #end=time.time()\n",
        "    #print(end-start)\n",
        "    #arr=np.array(arr)/255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m7qDi5bNwI7"
      },
      "source": [
        "for dirpathed,dirnamed,file in os.walk(\"./Days_and_Time\"):\n",
        "   z=0\n",
        "   for class_ in dirnamed:\n",
        "        for dirpath,dirname,files in os.walk(os.path.join(dirpathed,class_)):\n",
        "              for i in files:\n",
        "                    pather=os.path.join(dirpath,i)\n",
        "                    z+=1\n",
        "                    print(\"................ {} th Video...........\".format(z))\n",
        "                    video_array_maker(pather)\n",
        "        print(\".............{} over..........\".format(class_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoyXusE2OUw_"
      },
      "source": [
        "! pip install keras-video-generators\n",
        "import os\n",
        "import glob\n",
        "import keras\n",
        "from keras_video import VideoFrameGenerator\n",
        "# use sub directories names as classes\n",
        "import tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fz_-v7LzOmDo",
        "outputId": "e5a80574-321d-4523-94b6-1b37ecbccf47"
      },
      "source": [
        "classes = [i.split(os.path.sep)[2] for i in glob.glob('./Output/*')]\n",
        "classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['84. Evening',\n",
              " '86. Time',\n",
              " '81. Second',\n",
              " '83. Afternoon',\n",
              " '82. Morning',\n",
              " '85. Night']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxiUgU5cOn7_"
      },
      "source": [
        "data_aug = tensorflow.keras.preprocessing.image.ImageDataGenerator(rescale=1/255,horizontal_flip=True,width_shift_range=3.0,\n",
        "                                                                   height_shift_range=3.0,brightness_range=(0.2,1),)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JslGG97lQgjJ"
      },
      "source": [
        "\n",
        "# ImageDataGenerator\n",
        "datagen = tensorflow.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rotation_range=10, # rotation\n",
        "        width_shift_range=0.3, # horizontal shift\n",
        "        height_shift_range=0.2, # vertical shift\n",
        "        zoom_range=0.2, # zoom\n",
        "        horizontal_flip=True, # horizontal flip\n",
        "        brightness_range=[0.5,1.5]) # brightness"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3I2QHg1tSnZy",
        "outputId": "a28ee4ff-29e5-4fb9-9df9-baca533b2f20"
      },
      "source": [
        "\n",
        "# some global params\n",
        "SIZE = (224,224)\n",
        "CHANNELS = 3\n",
        "NBFRAME = 45\n",
        "BS = 2\n",
        "# pattern to get videos and classes\n",
        "glob_pattern='./Output/{classname}/*'\n",
        "# for data augmentation\n",
        "\n",
        "# Create video frame generator\n",
        "train = VideoFrameGenerator(\n",
        "    classes=classes, \n",
        "    glob_pattern=glob_pattern,\n",
        "    nb_frames=NBFRAME,\n",
        "    split_val=.2, \n",
        "    shuffle=True,\n",
        "    batch_size=BS,\n",
        "    target_shape=SIZE,\n",
        "    nb_channel=CHANNELS,\n",
        "    transformation=datagen,\n",
        "    use_frame_cache=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class 81. Second, validation count: 3, train count: 12\n",
            "class 82. Morning, validation count: 2, train count: 12\n",
            "class 83. Afternoon, validation count: 2, train count: 12\n",
            "class 84. Evening, validation count: 2, train count: 12\n",
            "class 85. Night, validation count: 3, train count: 12\n",
            "class 86. Time, validation count: 3, train count: 12\n",
            "Total data: 6 classes for 72 files for train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kB1sfFDSoUc"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM,Flatten, TimeDistributed, Conv2D, Dropout,Input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwXtVPN8rK_P"
      },
      "source": [
        "Model=None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yiIuO9LTdbs"
      },
      "source": [
        "mobilenet = tf.keras.applications.mobilenet.MobileNet(\n",
        "        include_top=False,\n",
        "        input_shape=(224,224,3),\n",
        "        weights='imagenet')\n",
        "    # Keep 9 layers to train\n",
        "trainable = 14\n",
        "for layer in mobilenet.layers[:-trainable]:\n",
        "    layer.trainable = False\n",
        "for layer in mobilenet.layers[-trainable:]:\n",
        "    layer.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqRC5lUDTfbu",
        "outputId": "cb1df64d-b3f9-4004-9a91-44acec749176"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(TimeDistributed(mobilenet ,input_shape=(45,224,224,3)))\n",
        "model.add(TimeDistributed( Flatten()))\n",
        "model.add(LSTM(128, activation='relu', return_sequences=False)) \n",
        "model.add(Dense(64,activation=\"relu\"))\n",
        "model.add(Dense(6,activation=\"softmax\")) \n",
        "model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(), metrics=tf.keras.metrics.Accuracy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZbXdvTHTi5f",
        "outputId": "d12b1080-dd9b-4451-bd47-c5bb53db1ec5"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "time_distributed_12 (TimeDis (None, 45, 7, 7, 1024)    3228864   \n",
            "_________________________________________________________________\n",
            "time_distributed_13 (TimeDis (None, 45, 50176)         0         \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 128)               25756160  \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 6)                 390       \n",
            "=================================================================\n",
            "Total params: 28,993,670\n",
            "Trainable params: 27,358,662\n",
            "Non-trainable params: 1,635,008\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4OUtvBjTpWx",
        "outputId": "69c3bee6-2a27-4b8f-b8af-5cb3c4f324af"
      },
      "source": [
        "valid = train.get_validation_generator()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total data: 6 classes for 15 files for validation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcicGqWzTrYH",
        "outputId": "a674d96f-12d8-4a64-fc60-35afa09b9542"
      },
      "source": [
        "model.fit(\n",
        "    train,\n",
        "    validation_data=valid,\n",
        "    verbose=1,\n",
        "    epochs=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "36/36 [==============================] - 47s 1s/step - loss: 1012.9003 - accuracy: 0.5712 - val_loss: 3068.8098 - val_accuracy: 0.6667\n",
            "Epoch 2/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 5374.8769 - accuracy: 0.6792 - val_loss: 28174.1113 - val_accuracy: 0.7381\n",
            "Epoch 3/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 27580.9482 - accuracy: 0.7023 - val_loss: 23613.4121 - val_accuracy: 0.7143\n",
            "Epoch 4/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 7001.0860 - accuracy: 0.7704 - val_loss: 6383.9175 - val_accuracy: 0.7381\n",
            "Epoch 5/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 5598.2159 - accuracy: 0.6960 - val_loss: 5641.5952 - val_accuracy: 0.7143\n",
            "Epoch 6/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 4613.1318 - accuracy: 0.6941 - val_loss: 6458.4888 - val_accuracy: 0.6786\n",
            "Epoch 7/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 2388.8708 - accuracy: 0.7111 - val_loss: 1406.3448 - val_accuracy: 0.7500\n",
            "Epoch 8/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 1015.0819 - accuracy: 0.7077 - val_loss: 2681.3972 - val_accuracy: 0.7500\n",
            "Epoch 9/20\n",
            "36/36 [==============================] - 45s 1s/step - loss: 2532.0063 - accuracy: 0.6818 - val_loss: 4143.8706 - val_accuracy: 0.6905\n",
            "Epoch 10/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 6450.2710 - accuracy: 0.7218 - val_loss: 2820.7029 - val_accuracy: 0.7024\n",
            "Epoch 11/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 2339.9955 - accuracy: 0.7204 - val_loss: 2978.7791 - val_accuracy: 0.7500\n",
            "Epoch 12/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 3302.0386 - accuracy: 0.7356 - val_loss: 37241.8203 - val_accuracy: 0.7381\n",
            "Epoch 13/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 27335.0656 - accuracy: 0.7446 - val_loss: 25955.6602 - val_accuracy: 0.6905\n",
            "Epoch 14/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 13553.4634 - accuracy: 0.7067 - val_loss: 4355.0024 - val_accuracy: 0.6905\n",
            "Epoch 15/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 2384.8737 - accuracy: 0.7023 - val_loss: 284.7100 - val_accuracy: 0.6548\n",
            "Epoch 16/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 852.8149 - accuracy: 0.7087 - val_loss: 795.8287 - val_accuracy: 0.6548\n",
            "Epoch 17/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 721.5264 - accuracy: 0.7145 - val_loss: 605.9991 - val_accuracy: 0.6667\n",
            "Epoch 18/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 613.4553 - accuracy: 0.6540 - val_loss: 610.0289 - val_accuracy: 0.6786\n",
            "Epoch 19/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 546.2670 - accuracy: 0.6337 - val_loss: 699.6952 - val_accuracy: 0.6548\n",
            "Epoch 20/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 416.1526 - accuracy: 0.6791 - val_loss: 578.6781 - val_accuracy: 0.6905\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc3199ce910>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcyDgUs9Tu5s",
        "outputId": "cb688881-3202-4fa3-fd62-e4dadda8e543"
      },
      "source": [
        "model.save(\"6classes\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: 6classes/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mWcGMSQaGcA",
        "outputId": "8c46fff6-63fe-4b5c-ac94-14af8922bcfc"
      },
      "source": [
        "model.save(\"my_model1\",save_format=\"tf\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model1/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zanuX7X7bMOM",
        "outputId": "562fa06f-c6e3-4121-bc46-0cf36d7a8c3e"
      },
      "source": [
        "checkmodel = keras.models.load_model('/content/6classes')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KAmwjy_bsOB",
        "outputId": "5fa5186d-fca2-4648-8689-5e5116c03b98"
      },
      "source": [
        "import os\n",
        " \n",
        "file_size = os.path.getsize('/content/6classes/variables/variables.data-00000-of-00001')\n",
        "print(\"File Size is :\", file_size, \"bytes\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File Size is : 334904662 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-qwrenMp8si",
        "outputId": "75180b03-f968-4d1a-888f-c680584b0775"
      },
      "source": [
        "334904662/1000000"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "334.904662"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eehiN64fxol"
      },
      "source": [
        "# Deploying Section :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXSri2QKcZMx"
      },
      "source": [
        "def video_array_maker(pather,height=224,width=224):\n",
        "  videodata = skvideo.io.vread(pather)  \n",
        "  \n",
        "  #outpath=os.path.join(\"./Output\",pather.split(\"/\")[2],os.path.split(pather)[1])\n",
        "  outpath=os.path.join(\"./test\",pather.split(\"/\")[2],os.path.split(pather)[1])\n",
        "  out = cv2.VideoWriter(outpath,cv2.VideoWriter_fourcc('M','J','P','G'), 10, (width,height))\n",
        "  #start=time.time()\n",
        "\n",
        "  with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
        "#    arr=[]\n",
        "    actualframe=len(videodata)\n",
        "    print(\"Actual frame {}\".format(actualframe))\n",
        "    if actualframe >=45:\n",
        "          for i in range (actualframe):\n",
        "            x=round (actualframe/(45)  * i)\n",
        "            if x >=actualframe:\n",
        "                    break\n",
        "            else:\n",
        "                frame =videodata[x]\n",
        "                frame =cv2.resize(frame,(width,height),interpolation=cv2.INTER_AREA)\n",
        "                results = holistic.process(frame)  \n",
        "\n",
        "                output = pose_estimation(frame,results)\n",
        "                output =cv2.cvtColor(output,cv2.COLOR_BGR2RGB)\n",
        "#                arr.append(output)\n",
        "                out.write(output)               \n",
        "    else:\n",
        "          for i in range(actualframe):\n",
        "              frame=videodata[i]\n",
        "              frame=cv2.resize(frame,(width,height),interpolation=cv2.INTER_AREA)\n",
        "              results = holistic.process(frame)  \n",
        "              output = pose_estimation(frame,results)\n",
        "              output =cv2.cvtColor(output,cv2.COLOR_BGR2RGB)\n",
        " #             arr.append(output)\n",
        "              out.write(output)\n",
        "          for i in range(45-actualframe):\n",
        "              \n",
        "              newframe=np.zeros(shape=(height,width,3))\n",
        "              \n",
        "#              arr.append(newframe)\n",
        "              out.write(np.uint8(newframe))\n",
        "    out.release()\n",
        "    print(\"File Created : {}\".format(outpath))\n",
        "    #end=time.time()\n",
        "    #print(end-start)\n",
        "    #arr=np.array(arr)/255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYjgZ5DucfxE",
        "outputId": "cbe9d98f-204b-4380-fb1a-bd9ee465fc88"
      },
      "source": [
        "aftpath=\"/content/afternoon.mp4\"\n",
        "video_array_maker(aftpath)\n",
        "morpath=\"/content/morning.mp4\"\n",
        "video_array_maker(morpath)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual frame 77\n",
            "File Created : ./test/afternoon.mp4/afternoon.mp4\n",
            "Actual frame 81\n",
            "File Created : ./test/morning.mp4/morning.mp4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWfUoUFneSfj"
      },
      "source": [
        "#os.makedirs(\"./test/afternoon.mp4\")\n",
        "os.makedirs(\"./test/time.mp4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egd6JkZqfQ69",
        "outputId": "5ef99a61-7fed-4463-d6fa-7f9c0ac456c5"
      },
      "source": [
        "timepath=\"/content/time.mp4\"\n",
        "video_array_maker(timepath)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual frame 100\n",
            "File Created : ./test/time.mp4/time.mp4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBjlzelzfrvd",
        "outputId": "2e8bcbae-43d1-4b9e-dd96-b5a47feb8acc"
      },
      "source": [
        "aft =skvideo.io.vread(\"./test/afternoon.mp4/afternoon.mp4\")\n",
        "aft.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBJ6ZfUNg-Bd",
        "outputId": "957a0fda-dab7-42d2-f6f9-f776015f8f79"
      },
      "source": [
        "mor =skvideo.io.vread(\"/content/test/morning.mp4/morning.mp4\")\n",
        "mor.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pu9PUtrxkyc2",
        "outputId": "0d13e3e7-2265-4733-fa51-636578a2ba02"
      },
      "source": [
        "time=skvideo.io.vread(\"/content/test/time.mp4/time.mp4\")\n",
        "time.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGVdNgGMiORb"
      },
      "source": [
        "a=[]\n",
        "a.append(aft)\n",
        "a.append(mor)\n",
        "a.append(time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKsj1DRoiTs1",
        "outputId": "709c5826-f219-4624-9bd7-82397dcbe1dd"
      },
      "source": [
        "a=np.array(a)\n",
        "a.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 45, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNFf79s1gO5q"
      },
      "source": [
        "x=model.predict(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVU2sm5eiTPL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPZUVptWgUtE",
        "outputId": "739345b3-b4ed-4047-f1a7-c9b7f16d0af8"
      },
      "source": [
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opat4zvWi1bF",
        "outputId": "28498c2c-3887-46c6-c24b-f57cacdc65f8"
      },
      "source": [
        "train.classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['81. Second',\n",
              " '82. Morning',\n",
              " '83. Afternoon',\n",
              " '84. Evening',\n",
              " '85. Night',\n",
              " '86. Time']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcdXCCo4i854",
        "outputId": "9a363a23-4974-491f-963c-291291f29264"
      },
      "source": [
        "classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['81. Second',\n",
              " '82. Morning',\n",
              " '83. Afternoon',\n",
              " '84. Evening',\n",
              " '85. Night',\n",
              " '86. Time']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T__fe_qujApK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}