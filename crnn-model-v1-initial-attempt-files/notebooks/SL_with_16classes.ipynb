{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SL_with_16classes.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "K-pIKzwqu0lJ",
        "w0CBSgreta47",
        "hhSvgbc_tibB",
        "iX7WYFd3trFp",
        "bJi94hSXt7-n",
        "8UyHatb9uUiu",
        "wixeYaPUuilR",
        "jMFvc01urxG6",
        "uihQ1Fz1sYZL"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-pIKzwqu0lJ"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N13aUr2BHLjX"
      },
      "source": [
        "import shutil\n",
        "shutil.rmtree(\"/content/sample_data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrJqM_BgHTmo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce0887b9-5682-4764-cfee-7e1d2a645e7b"
      },
      "source": [
        "! pip install mediapipe\n",
        "! pip install sk-video\n",
        "! pip install keras-video-generators\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n",
        "import skvideo.io\n",
        "import cv2 \n",
        "import mediapipe as mp\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import keras\n",
        "from keras_video import VideoFrameGenerator\n",
        "# use sub directories names as classes\n",
        "import tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM,Flatten, TimeDistributed, Conv2D, Dropout,Input"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mediapipe\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/42/af2507a86a81e4cce0d3adcb764a755f397238d0c7bee2d99794fdca2fc5/mediapipe-0.8.3.1-cp37-cp37m-manylinux2014_x86_64.whl (47.4MB)\n",
            "\u001b[K     |████████████████████████████████| 47.4MB 115kB/s \n",
            "\u001b[?25hCollecting dataclasses\n",
            "  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n",
            "Requirement already satisfied: protobuf>=3.11.4 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.12.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.19.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mediapipe) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.15.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from mediapipe) (0.36.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from mediapipe) (4.1.2.30)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (20.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.11.4->mediapipe) (56.0.0)\n",
            "Installing collected packages: dataclasses, mediapipe\n",
            "Successfully installed dataclasses-0.6 mediapipe-0.8.3.1\n",
            "Collecting sk-video\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/3f/ce848b8b2062ad1ccf1449094a740c775f6c761339f411e44f1e090f23a7/sk_video-1.1.10-py2.py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sk-video) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sk-video) (1.19.5)\n",
            "Installing collected packages: sk-video\n",
            "Successfully installed sk-video-1.1.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwaGfFBm7Frt"
      },
      "source": [
        "shutil.rmtree(\"/content/sample_data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0CBSgreta47"
      },
      "source": [
        "## Downloading and Unzipping Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoEjku8dHWWs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf9bc120-2ec5-4d27-9460-694a74ba0932"
      },
      "source": [
        "! wget https://zenodo.org/record/4010759/files/Greetings_1of2.zip\n",
        "! wget https://zenodo.org/record/4010759/files/Greetings_2of2.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-01 12:34:37--  https://zenodo.org/record/4010759/files/Greetings_1of2.zip\n",
            "Resolving zenodo.org (zenodo.org)... 137.138.76.77\n",
            "Connecting to zenodo.org (zenodo.org)|137.138.76.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1573733886 (1.5G) [application/octet-stream]\n",
            "Saving to: ‘Greetings_1of2.zip’\n",
            "\n",
            "Greetings_1of2.zip  100%[===================>]   1.46G  18.3MB/s    in 1m 45s  \n",
            "\n",
            "2021-05-01 12:36:24 (14.2 MB/s) - ‘Greetings_1of2.zip’ saved [1573733886/1573733886]\n",
            "\n",
            "--2021-05-01 12:36:24--  https://zenodo.org/record/4010759/files/Greetings_2of2.zip\n",
            "Resolving zenodo.org (zenodo.org)... 137.138.76.77\n",
            "Connecting to zenodo.org (zenodo.org)|137.138.76.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1208700458 (1.1G) [application/octet-stream]\n",
            "Saving to: ‘Greetings_2of2.zip’\n",
            "\n",
            "Greetings_2of2.zip  100%[===================>]   1.12G  18.6MB/s    in 89s     \n",
            "\n",
            "2021-05-01 12:37:54 (13.0 MB/s) - ‘Greetings_2of2.zip’ saved [1208700458/1208700458]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4w4xU4VRnMDf"
      },
      "source": [
        "! unzip Greetings_1of2.zip\n",
        "! unzip Greetings_2of2.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "376yO7ypIjWP",
        "outputId": "da48a5a1-68db-4354-b7bc-935ee8f9bc29"
      },
      "source": [
        "! wget https://zenodo.org/record/4010759/files/Pronouns_1of2.zip\n",
        "! wget https://zenodo.org/record/4010759/files/Pronouns_2of2.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-01 12:38:25--  https://zenodo.org/record/4010759/files/Pronouns_1of2.zip\n",
            "Resolving zenodo.org (zenodo.org)... 137.138.76.77\n",
            "Connecting to zenodo.org (zenodo.org)|137.138.76.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1419853451 (1.3G) [application/octet-stream]\n",
            "Saving to: ‘Pronouns_1of2.zip’\n",
            "\n",
            "Pronouns_1of2.zip   100%[===================>]   1.32G  4.82MB/s    in 2m 20s  \n",
            "\n",
            "2021-05-01 12:40:46 (9.68 MB/s) - ‘Pronouns_1of2.zip’ saved [1419853451/1419853451]\n",
            "\n",
            "--2021-05-01 12:40:46--  https://zenodo.org/record/4010759/files/Pronouns_2of2.zip\n",
            "Resolving zenodo.org (zenodo.org)... 137.138.76.77\n",
            "Connecting to zenodo.org (zenodo.org)|137.138.76.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 946837765 (903M) [application/octet-stream]\n",
            "Saving to: ‘Pronouns_2of2.zip’\n",
            "\n",
            "Pronouns_2of2.zip   100%[===================>] 902.97M  10.7MB/s    in 66s     \n",
            "\n",
            "2021-05-01 12:41:54 (13.7 MB/s) - ‘Pronouns_2of2.zip’ saved [946837765/946837765]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnufwvsFpn9f"
      },
      "source": [
        "!unzip Pronouns_1of2.zip\n",
        "!unzip Pronouns_2of2.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "za4vjLM3q-Yi"
      },
      "source": [
        "shutil.rmtree(\"/content/Pronouns/46. you (plural)\")\n",
        "shutil.rmtree(\"/content/Pronouns/44. it\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJ1s5xo09Cqf"
      },
      "source": [
        "os.makedirs(\"/content/Input\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtn4nzh7vOFp"
      },
      "source": [
        "### Adding our Own Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRRgUNHHscFR",
        "outputId": "6a954777-c672-4ccc-9711-1b2d86c4f546"
      },
      "source": [
        "wordtype=[\"Greetings\",\"Pronouns\"]\n",
        "\n",
        "for i in wordtype:\n",
        "   for dirpath,dirfile,filename in os.walk(os.path.join(\"/content\",i)):\n",
        "     print(dirfile)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['50. Alright', '55. Thank you', '56. Pleased', '53. Good evening', '54. Good night', '48. Hello', '51. Good Morning', '52. Good afternoon', '49. How are you']\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "['45. we', '42. he', '43. she', '47. they', '40. I', '41. you']\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "['.ipynb_checkpoints']\n",
            "[]\n",
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BUhFZPhumn9"
      },
      "source": [
        "d=['/content/Greetings',\"/content/Pronouns/\"]\n",
        "target_dir = '/content/Input'\n",
        "\n",
        "for i in d:\n",
        "    file_names = os.listdir(i)\n",
        "    for file_name in file_names:\n",
        "        shutil.move(os.path.join(i, file_name), target_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVuW52qswNFT"
      },
      "source": [
        "os.makedirs(\"/content/Output\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l6TX8Cstgz5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhSvgbc_tibB"
      },
      "source": [
        "## Initializing Holistic Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWkqTAG7v-qN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "9b4f5310-9e92-4a9b-d9b0-042dc089b722"
      },
      "source": [
        "mp_drawing=mp.solutions.drawing_utils\n",
        "mp_holistic=mp.solutions.holistic\n",
        "\n",
        "def pose_estimation(image,results):\n",
        "        \n",
        "        # 1. Draw face landmarks\n",
        "        #mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS, \n",
        "        #                         mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
        "        #                         mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
        "        #                         )\n",
        "        \n",
        "        # 2. Right hand\n",
        "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
        "                                 mp_drawing.DrawingSpec(color=(102,255,51), thickness=3, circle_radius=4),\n",
        "                                 mp_drawing.DrawingSpec(color=(255,255,255), thickness=2, circle_radius=2)\n",
        "                                 )\n",
        "\n",
        "        # 3. Left Hand\n",
        "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
        "                                 mp_drawing.DrawingSpec(color=(102,255,51), thickness=3, circle_radius=4),\n",
        "                                 mp_drawing.DrawingSpec(color=(255,255,255), thickness=2, circle_radius=2)\n",
        "                                 )\n",
        "\n",
        "        # 4. Pose Detections\n",
        "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
        "                                 mp_drawing.DrawingSpec(color=(255,255,0), thickness=2, circle_radius=4),\n",
        "                                 mp_drawing.DrawingSpec(color=(255,255,255), thickness=2, circle_radius=2)\n",
        "                                 )\n",
        "                        \n",
        "        return image"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5388709af2d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmp_drawing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrawing_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmp_holistic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholistic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpose_estimation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mp' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iX7WYFd3trFp"
      },
      "source": [
        "## Applying Holistic Model on Video and Resizing it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMGcVtsFwJom"
      },
      "source": [
        "def video_array_maker(pather,height=224,width=224):\n",
        "  videodata = skvideo.io.vread(pather)  \n",
        "  outpath=os.path.join(\"./Output\",pather.split(\"/\")[3],os.path.split(pather)[1])\n",
        "  out = cv2.VideoWriter(outpath,cv2.VideoWriter_fourcc('M','J','P','G'), 10, (width,height))\n",
        "  #start=time.time()\n",
        "\n",
        "  with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
        "#    arr=[]\n",
        "    actualframe=len(videodata)\n",
        "    #print(\"Actual frame {}\".format(actualframe))\n",
        "    if actualframe >=45:\n",
        "          for i in range (actualframe):\n",
        "            x=round (actualframe/(45)  * i)\n",
        "            if x >=actualframe:\n",
        "                    break\n",
        "            else:\n",
        "                frame =videodata[x]\n",
        "                #frame =cv2.resize(frame,(width,height),interpolation=cv2.INTER_AREA)\n",
        "                results = holistic.process(frame)  \n",
        "\n",
        "                output = pose_estimation(frame,results)\n",
        "                output =cv2.resize(output,(width,height),interpolation=cv2.INTER_AREA)\n",
        "                output =cv2.cvtColor(output,cv2.COLOR_BGR2RGB)\n",
        "#                arr.append(output)\n",
        "                out.write(output)               \n",
        "    else:\n",
        "          for i in range(actualframe):\n",
        "              frame=videodata[i]\n",
        "              frame=cv2.resize(frame,(width,height),interpolation=cv2.INTER_AREA)\n",
        "              results = holistic.process(frame)  \n",
        "              output = pose_estimation(frame,results)\n",
        "              output =cv2.cvtColor(output,cv2.COLOR_BGR2RGB)\n",
        "              out.write(output)\n",
        "          for i in range(45-actualframe):\n",
        "              \n",
        "              newframe=np.zeros(shape=(height,width,3))\n",
        "              \n",
        "\n",
        "              out.write(np.uint8(newframe))\n",
        "    out.release()\n",
        "    #print(\"File Created : {}\".format(outpath))\n",
        "    os.remove(pather)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGZAzN8Uwtxy"
      },
      "source": [
        "for dirpathed,dirnamed,file in os.walk(\"/content/Input\"):\n",
        "   z=0\n",
        "   for class_ in dirnamed:\n",
        "        for dirpath,dirname,files in os.walk(os.path.join(dirpathed,class_)):\n",
        "              for i in files:\n",
        "                    pather=os.path.join(dirpath,i)\n",
        "                    print(pather)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX1dnoKTxoI5"
      },
      "source": [
        "os.removedirs(\"/content/Input/40. I/.ipynb_checkpoints\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f24JHGkDzQ0y"
      },
      "source": [
        "for dirpathed,dirnamed,file in os.walk(\"/content/Input\"):\n",
        "    for class_  in dirnamed:\n",
        "      os.makedirs(os.path.join(\"/content/Output\",class_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoePL0VPw9tl",
        "outputId": "da0ba68f-aad3-4f54-cfea-cd86c4096acc"
      },
      "source": [
        "z=0\n",
        "for dirpathed,dirnamed,file in os.walk(\"/content/Input\"):\n",
        " for class_  in dirnamed:\n",
        "   for dirpath,dirname,files in os.walk(os.path.join(dirpathed,class_)):\n",
        "     for i in files:\n",
        "          pather=os.path.join(dirpath,i)\n",
        "          z+=1\n",
        "          print(\"..{} th Video..\".format(z))\n",
        "          video_array_maker(pather)\n",
        "   print(\".............{} over..........\".format(class_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "..1 th Video..\n",
            "..2 th Video..\n",
            "..3 th Video..\n",
            "..4 th Video..\n",
            "..5 th Video..\n",
            "..6 th Video..\n",
            "..7 th Video..\n",
            "..8 th Video..\n",
            "..9 th Video..\n",
            "..10 th Video..\n",
            "..11 th Video..\n",
            "..12 th Video..\n",
            "..13 th Video..\n",
            "..14 th Video..\n",
            "..15 th Video..\n",
            "..16 th Video..\n",
            "..17 th Video..\n",
            "..18 th Video..\n",
            "..19 th Video..\n",
            "..20 th Video..\n",
            "..21 th Video..\n",
            ".............45. we over..........\n",
            "..22 th Video..\n",
            "..23 th Video..\n",
            "..24 th Video..\n",
            "..25 th Video..\n",
            "..26 th Video..\n",
            "..27 th Video..\n",
            "..28 th Video..\n",
            "..29 th Video..\n",
            "..30 th Video..\n",
            "..31 th Video..\n",
            "..32 th Video..\n",
            "..33 th Video..\n",
            "..34 th Video..\n",
            "..35 th Video..\n",
            "..36 th Video..\n",
            "..37 th Video..\n",
            "..38 th Video..\n",
            "..39 th Video..\n",
            "..40 th Video..\n",
            "..41 th Video..\n",
            "..42 th Video..\n",
            ".............50. Alright over..........\n",
            "..43 th Video..\n",
            "..44 th Video..\n",
            "..45 th Video..\n",
            "..46 th Video..\n",
            "..47 th Video..\n",
            "..48 th Video..\n",
            "..49 th Video..\n",
            "..50 th Video..\n",
            "..51 th Video..\n",
            "..52 th Video..\n",
            "..53 th Video..\n",
            "..54 th Video..\n",
            "..55 th Video..\n",
            "..56 th Video..\n",
            "..57 th Video..\n",
            "..58 th Video..\n",
            "..59 th Video..\n",
            "..60 th Video..\n",
            "..61 th Video..\n",
            "..62 th Video..\n",
            "..63 th Video..\n",
            ".............42. he over..........\n",
            "..64 th Video..\n",
            "..65 th Video..\n",
            "..66 th Video..\n",
            "..67 th Video..\n",
            "..68 th Video..\n",
            "..69 th Video..\n",
            "..70 th Video..\n",
            "..71 th Video..\n",
            "..72 th Video..\n",
            "..73 th Video..\n",
            "..74 th Video..\n",
            "..75 th Video..\n",
            "..76 th Video..\n",
            "..77 th Video..\n",
            "..78 th Video..\n",
            "..79 th Video..\n",
            "..80 th Video..\n",
            "..81 th Video..\n",
            "..82 th Video..\n",
            "..83 th Video..\n",
            "..84 th Video..\n",
            ".............55. Thank you over..........\n",
            "..85 th Video..\n",
            "..86 th Video..\n",
            "..87 th Video..\n",
            "..88 th Video..\n",
            "..89 th Video..\n",
            "..90 th Video..\n",
            "..91 th Video..\n",
            "..92 th Video..\n",
            "..93 th Video..\n",
            "..94 th Video..\n",
            "..95 th Video..\n",
            "..96 th Video..\n",
            "..97 th Video..\n",
            "..98 th Video..\n",
            "..99 th Video..\n",
            "..100 th Video..\n",
            "..101 th Video..\n",
            "..102 th Video..\n",
            "..103 th Video..\n",
            "..104 th Video..\n",
            "..105 th Video..\n",
            ".............43. she over..........\n",
            "..106 th Video..\n",
            "..107 th Video..\n",
            "..108 th Video..\n",
            "..109 th Video..\n",
            "..110 th Video..\n",
            "..111 th Video..\n",
            "..112 th Video..\n",
            "..113 th Video..\n",
            "..114 th Video..\n",
            "..115 th Video..\n",
            "..116 th Video..\n",
            "..117 th Video..\n",
            "..118 th Video..\n",
            "..119 th Video..\n",
            "..120 th Video..\n",
            "..121 th Video..\n",
            "..122 th Video..\n",
            "..123 th Video..\n",
            "..124 th Video..\n",
            "..125 th Video..\n",
            "..126 th Video..\n",
            ".............56. Pleased over..........\n",
            "..127 th Video..\n",
            "..128 th Video..\n",
            "..129 th Video..\n",
            "..130 th Video..\n",
            "..131 th Video..\n",
            "..132 th Video..\n",
            "..133 th Video..\n",
            "..134 th Video..\n",
            "..135 th Video..\n",
            "..136 th Video..\n",
            "..137 th Video..\n",
            "..138 th Video..\n",
            "..139 th Video..\n",
            "..140 th Video..\n",
            "..141 th Video..\n",
            "..142 th Video..\n",
            "..143 th Video..\n",
            "..144 th Video..\n",
            "..145 th Video..\n",
            "..146 th Video..\n",
            "..147 th Video..\n",
            ".............47. they over..........\n",
            "..148 th Video..\n",
            "..149 th Video..\n",
            "..150 th Video..\n",
            "..151 th Video..\n",
            "..152 th Video..\n",
            "..153 th Video..\n",
            "..154 th Video..\n",
            "..155 th Video..\n",
            "..156 th Video..\n",
            "..157 th Video..\n",
            "..158 th Video..\n",
            "..159 th Video..\n",
            "..160 th Video..\n",
            "..161 th Video..\n",
            "..162 th Video..\n",
            "..163 th Video..\n",
            "..164 th Video..\n",
            "..165 th Video..\n",
            "..166 th Video..\n",
            "..167 th Video..\n",
            "..168 th Video..\n",
            ".............53. Good evening over..........\n",
            "..169 th Video..\n",
            "..170 th Video..\n",
            "..171 th Video..\n",
            "..172 th Video..\n",
            "..173 th Video..\n",
            "..174 th Video..\n",
            "..175 th Video..\n",
            "..176 th Video..\n",
            "..177 th Video..\n",
            "..178 th Video..\n",
            "..179 th Video..\n",
            "..180 th Video..\n",
            "..181 th Video..\n",
            "..182 th Video..\n",
            "..183 th Video..\n",
            "..184 th Video..\n",
            "..185 th Video..\n",
            "..186 th Video..\n",
            "..187 th Video..\n",
            "..188 th Video..\n",
            "..189 th Video..\n",
            ".............54. Good night over..........\n",
            "..190 th Video..\n",
            "..191 th Video..\n",
            "..192 th Video..\n",
            "..193 th Video..\n",
            "..194 th Video..\n",
            "..195 th Video..\n",
            "..196 th Video..\n",
            "..197 th Video..\n",
            "..198 th Video..\n",
            "..199 th Video..\n",
            "..200 th Video..\n",
            "..201 th Video..\n",
            "..202 th Video..\n",
            "..203 th Video..\n",
            "..204 th Video..\n",
            "..205 th Video..\n",
            "..206 th Video..\n",
            "..207 th Video..\n",
            "..208 th Video..\n",
            "..209 th Video..\n",
            "..210 th Video..\n",
            ".............48. Hello over..........\n",
            "..211 th Video..\n",
            "..212 th Video..\n",
            "..213 th Video..\n",
            "..214 th Video..\n",
            "..215 th Video..\n",
            "..216 th Video..\n",
            "..217 th Video..\n",
            "..218 th Video..\n",
            "..219 th Video..\n",
            "..220 th Video..\n",
            "..221 th Video..\n",
            "..222 th Video..\n",
            "..223 th Video..\n",
            "..224 th Video..\n",
            "..225 th Video..\n",
            "..226 th Video..\n",
            "..227 th Video..\n",
            "..228 th Video..\n",
            "..229 th Video..\n",
            "..230 th Video..\n",
            "..231 th Video..\n",
            ".............40. I over..........\n",
            "..232 th Video..\n",
            "..233 th Video..\n",
            "..234 th Video..\n",
            "..235 th Video..\n",
            "..236 th Video..\n",
            "..237 th Video..\n",
            "..238 th Video..\n",
            "..239 th Video..\n",
            "..240 th Video..\n",
            "..241 th Video..\n",
            "..242 th Video..\n",
            "..243 th Video..\n",
            "..244 th Video..\n",
            "..245 th Video..\n",
            "..246 th Video..\n",
            "..247 th Video..\n",
            "..248 th Video..\n",
            "..249 th Video..\n",
            "..250 th Video..\n",
            "..251 th Video..\n",
            "..252 th Video..\n",
            ".............51. Good Morning over..........\n",
            "..253 th Video..\n",
            "..254 th Video..\n",
            "..255 th Video..\n",
            "..256 th Video..\n",
            "..257 th Video..\n",
            "..258 th Video..\n",
            "..259 th Video..\n",
            "..260 th Video..\n",
            "..261 th Video..\n",
            "..262 th Video..\n",
            "..263 th Video..\n",
            "..264 th Video..\n",
            "..265 th Video..\n",
            "..266 th Video..\n",
            "..267 th Video..\n",
            "..268 th Video..\n",
            "..269 th Video..\n",
            "..270 th Video..\n",
            "..271 th Video..\n",
            "..272 th Video..\n",
            "..273 th Video..\n",
            "..274 th Video..\n",
            ".............52. Good afternoon over..........\n",
            "..275 th Video..\n",
            "..276 th Video..\n",
            "..277 th Video..\n",
            "..278 th Video..\n",
            "..279 th Video..\n",
            "..280 th Video..\n",
            "..281 th Video..\n",
            "..282 th Video..\n",
            "..283 th Video..\n",
            "..284 th Video..\n",
            "..285 th Video..\n",
            "..286 th Video..\n",
            "..287 th Video..\n",
            "..288 th Video..\n",
            "..289 th Video..\n",
            "..290 th Video..\n",
            "..291 th Video..\n",
            "..292 th Video..\n",
            "..293 th Video..\n",
            "..294 th Video..\n",
            "..295 th Video..\n",
            ".............41. you over..........\n",
            "..296 th Video..\n",
            "..297 th Video..\n",
            "..298 th Video..\n",
            "..299 th Video..\n",
            "..300 th Video..\n",
            "..301 th Video..\n",
            "..302 th Video..\n",
            "..303 th Video..\n",
            "..304 th Video..\n",
            "..305 th Video..\n",
            "..306 th Video..\n",
            "..307 th Video..\n",
            "..308 th Video..\n",
            "..309 th Video..\n",
            "..310 th Video..\n",
            "..311 th Video..\n",
            "..312 th Video..\n",
            "..313 th Video..\n",
            "..314 th Video..\n",
            "..315 th Video..\n",
            "..316 th Video..\n",
            ".............49. How are you over..........\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJi94hSXt7-n"
      },
      "source": [
        "## Inserting \"None\" Class "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkanlOS_ysZw"
      },
      "source": [
        "os.makedirs(\"/content/Output/NoAction\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBl3PYgIChzs"
      },
      "source": [
        "def video_array_makeraction(pather,height=224,width=224):\n",
        "  videodata = skvideo.io.vread(pather)  \n",
        "  outpath=os.path.join(\"./Output/NoAction\",os.path.split(pather)[1])\n",
        "  out = cv2.VideoWriter(outpath,cv2.VideoWriter_fourcc('M','J','P','G'), 10, (width,height))\n",
        "  #start=time.time()\n",
        "\n",
        "  with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
        "#    arr=[]\n",
        "    actualframe=len(videodata)\n",
        "    #print(\"Actual frame {}\".format(actualframe))\n",
        "    if actualframe >=45:\n",
        "          for i in range (actualframe):\n",
        "            x=round (actualframe/(45)  * i)\n",
        "            if x >=actualframe:\n",
        "                    break\n",
        "            else:\n",
        "                frame =videodata[x]\n",
        "                frame =cv2.resize(frame,(width,height),interpolation=cv2.INTER_AREA)\n",
        "                results = holistic.process(frame)  \n",
        "\n",
        "                output = pose_estimation(frame,results)\n",
        "                output =cv2.cvtColor(output,cv2.COLOR_BGR2RGB)\n",
        "#                arr.append(output)\n",
        "                out.write(output)               \n",
        "    else:\n",
        "          for i in range(actualframe):\n",
        "              frame=videodata[i]\n",
        "              frame=cv2.resize(frame,(width,height),interpolation=cv2.INTER_AREA)\n",
        "              results = holistic.process(frame)  \n",
        "              output = pose_estimation(frame,results)\n",
        "              output =cv2.cvtColor(output,cv2.COLOR_BGR2RGB)\n",
        "              out.write(output)\n",
        "          for i in range(45-actualframe):\n",
        "              \n",
        "              newframe=np.zeros(shape=(height,width,3))\n",
        "              \n",
        "\n",
        "              out.write(np.uint8(newframe))\n",
        "    out.release()\n",
        "    #print(\"File Created : {}\".format(outpath))\n",
        "    os.remove(pather)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6NdmQSLD7cJ"
      },
      "source": [
        "!unzip /content/NoAction.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtyJZYQRCqYC"
      },
      "source": [
        "for dirpath,dirname,files in os.walk(\"/content/NoAction\"):\n",
        "  for i in files:\n",
        "    pather=os.path.join(dirpath,i)\n",
        "    video_array_makeraction(pather)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytHSdO2fw_vY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UyHatb9uUiu"
      },
      "source": [
        "## Video Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9qYXjHy5OKi",
        "outputId": "7eef9335-055e-4d78-8bc9-3806951a73eb"
      },
      "source": [
        "classes = [i.split(os.path.sep)[2] for i in glob.glob('./Output/*')]\n",
        "classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['45. we',\n",
              " '50. Alright',\n",
              " '42. he',\n",
              " '55. Thank you',\n",
              " '43. she',\n",
              " 'NoAction',\n",
              " '56. Pleased',\n",
              " '47. they',\n",
              " '53. Good evening',\n",
              " '54. Good night',\n",
              " '48. Hello',\n",
              " '40. I',\n",
              " '51. Good Morning',\n",
              " '52. Good afternoon',\n",
              " '41. you',\n",
              " '49. How are you']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwuXV7MUFBMH"
      },
      "source": [
        "\n",
        "# ImageDataGenerator\n",
        "datagen = tensorflow.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rotation_range=10, # rotation\n",
        "        width_shift_range=0.3, # horizontal shift\n",
        "        height_shift_range=0.2, # vertical shift\n",
        "        zoom_range=0.2, # zoom\n",
        "        horizontal_flip=True, # horizontal flip\n",
        "        brightness_range=[0.8,1.5]) # brightness"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pua8lQKUFDc7",
        "outputId": "93e01f8a-8075-4533-b228-7e6816b5d215"
      },
      "source": [
        "\n",
        "# some global params\n",
        "SIZE = (224,224)\n",
        "CHANNELS = 3\n",
        "NBFRAME = 45\n",
        "BS = 4\n",
        "# pattern to get videos and classes\n",
        "glob_pattern='./Output/{classname}/*'\n",
        "# for data augmentation\n",
        "\n",
        "# Create video frame generator\n",
        "train = VideoFrameGenerator(\n",
        "    classes=classes, \n",
        "    glob_pattern=glob_pattern,\n",
        "    nb_frames=NBFRAME,\n",
        "    split_val=.2, \n",
        "    shuffle=True,\n",
        "    batch_size=BS,\n",
        "    target_shape=SIZE,\n",
        "    nb_channel=CHANNELS,\n",
        "    transformation=datagen,\n",
        "    use_frame_cache=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class 40. I, validation count: 3, train count: 15\n",
            "class 41. you, validation count: 4, train count: 17\n",
            "class 42. he, validation count: 4, train count: 17\n",
            "class 43. she, validation count: 4, train count: 17\n",
            "class 45. we, validation count: 4, train count: 17\n",
            "class 47. they, validation count: 4, train count: 17\n",
            "class 48. Hello, validation count: 4, train count: 17\n",
            "class 49. How are you, validation count: 4, train count: 17\n",
            "class 50. Alright, validation count: 4, train count: 17\n",
            "class 51. Good Morning, validation count: 4, train count: 17\n",
            "class 52. Good afternoon, validation count: 4, train count: 18\n",
            "class 53. Good evening, validation count: 4, train count: 17\n",
            "class 54. Good night, validation count: 4, train count: 17\n",
            "class 55. Thank you, validation count: 4, train count: 17\n",
            "class 56. Pleased, validation count: 4, train count: 17\n",
            "class NoAction, validation count: 4, train count: 18\n",
            "Total data: 16 classes for 272 files for train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN3wav1LFG2M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wixeYaPUuilR"
      },
      "source": [
        "## Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nM1455jGkbT9"
      },
      "source": [
        "model=None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWOxP7UdFJwb"
      },
      "source": [
        "mobilenet = tf.keras.applications.mobilenet.MobileNet(\n",
        "        include_top=False,\n",
        "        input_shape=(224,224,3),\n",
        "        weights='imagenet')\n",
        "    # Keep 9 layers to train\n",
        "trainable = 14\n",
        "for layer in mobilenet.layers[:-trainable]:\n",
        "    layer.trainable = False\n",
        "for layer in mobilenet.layers[-trainable:]:\n",
        "    layer.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NOZa1JwFMqc",
        "outputId": "25591fd8-a77a-4158-be4a-5afa144fd32f"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(TimeDistributed(mobilenet ,input_shape=(45,224,224,3)))\n",
        "model.add(TimeDistributed( Flatten()))\n",
        "model.add(LSTM(128, activation='relu', return_sequences=False)) \n",
        "model.add(Dense(64,activation=\"relu\"))\n",
        "model.add(Dense(16,activation=\"softmax\")) \n",
        "model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(), metrics=tf.keras.metrics.Accuracy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biMTnRbkFPZS",
        "outputId": "60f5ac76-32e8-44b4-84fb-1f6b5820d4a5"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "time_distributed_12 (TimeDis (None, 45, 7, 7, 1024)    3228864   \n",
            "_________________________________________________________________\n",
            "time_distributed_13 (TimeDis (None, 45, 50176)         0         \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 128)               25756160  \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 16)                1040      \n",
            "=================================================================\n",
            "Total params: 28,994,320\n",
            "Trainable params: 27,359,312\n",
            "Non-trainable params: 1,635,008\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9KPIzTjFR2S",
        "outputId": "7d0b3d57-654c-4550-b149-0330c0aad558"
      },
      "source": [
        "valid = train.get_validation_generator()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total data: 16 classes for 63 files for validation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCDULeZ9FYL8"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jcfe_YFFjSn"
      },
      "source": [
        "checkpoint_filepath = '/content/checkpoint'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGOJ_MXgFUC1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09640196-a352-4a62-dbd5-2239203fc54d"
      },
      "source": [
        "model.fit(\n",
        "    train,\n",
        "    validation_data=valid,\n",
        "    verbose=1,\n",
        "    epochs=3)\n",
        "    #callbacks=model_checkpoint_callback)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "68/68 [==============================] - 141s 2s/step - loss: 6312.2564 - accuracy: 0.8137 - val_loss: 22759.5703 - val_accuracy: 0.8771\n",
            "Epoch 2/3\n",
            "68/68 [==============================] - 136s 2s/step - loss: 22866.2496 - accuracy: 0.8794 - val_loss: 32161.9688 - val_accuracy: 0.8771\n",
            "Epoch 3/3\n",
            "68/68 [==============================] - 136s 2s/step - loss: 22734.8194 - accuracy: 0.8839 - val_loss: 16226.6055 - val_accuracy: 0.8750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7eff52f55f90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HUKxbX0F_Fr",
        "outputId": "a30d94b1-a04d-4708-ae3c-a2d909f2e963"
      },
      "source": [
        "model2=tensorflow.keras.models.load_model(\"/content/checkpoint\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQPaXhwTMfSN",
        "outputId": "a41f6dc7-0450-47c9-b2f3-49b16cfe8dae"
      },
      "source": [
        "print(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9IMPeTpRVh6",
        "outputId": "0cd78d81-3597-4515-e024-d2b071609a56"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "time_distributed_6 (TimeDist (None, 45, 5, 5, 2048)    21802784  \n",
            "_________________________________________________________________\n",
            "time_distributed_7 (TimeDist (None, 45, 51200)         0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 128)               26280448  \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 16)                1040      \n",
            "=================================================================\n",
            "Total params: 48,092,528\n",
            "Trainable params: 26,684,240\n",
            "Non-trainable params: 21,408,288\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMFvc01urxG6"
      },
      "source": [
        "## Checking out Model Performance on Unseen Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mbx73Sq1aM92"
      },
      "source": [
        "!unzip Tester.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2bw6TajuyC9"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gk1HSIT6bwsJ",
        "outputId": "d0babae6-20ea-45b5-8b79-3a362b433468"
      },
      "source": [
        "for i,j,k in os.walk(\"/content/Tester\"):\n",
        "  for m in k:\n",
        "    print(os.path.join(\"/content/Tester\",m))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Tester/WhatsApp Video 2021-05-01 at 8.17.52 PM (1).mp4\n",
            "/content/Tester/WhatsApp Video 2021-05-01 at 8.17.53 PM.mp4\n",
            "/content/Tester/WhatsApp Video 2021-05-01 at 8.17.51 PM.mp4\n",
            "/content/Tester/WhatsApp Video 2021-05-01 at 8.17.52 PM (2).mp4\n",
            "/content/Tester/WhatsApp Video 2021-05-01 at 8.17.52 PM.mp4\n",
            "/content/Tester/WhatsApp Video 2021-05-01 at 8.17.51 PM (1).mp4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMrzXAjzcM4E"
      },
      "source": [
        "#os.makedirs(\"/content/Tester2\")\n",
        "def video_array_makeraction(pather,height=224,width=224):\n",
        "  videodata = skvideo.io.vread(pather)  \n",
        "  outpath=os.path.join(\"/content/Tester2\",os.path.split(pather)[1])\n",
        "  out = cv2.VideoWriter(outpath,cv2.VideoWriter_fourcc('M','J','P','G'), 10, (width,height))\n",
        "  #start=time.time()\n",
        "\n",
        "  with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
        "#    arr=[]\n",
        "    actualframe=len(videodata)\n",
        "    print(\"Actual frame {}\".format(actualframe))\n",
        "    if actualframe >=45:\n",
        "          for i in range (actualframe):\n",
        "            x=round (actualframe/(45)  * i)\n",
        "            if x >=actualframe:\n",
        "                    break\n",
        "            else:\n",
        "                frame =videodata[x]\n",
        "                frame =cv2.resize(frame,(width,height),interpolation=cv2.INTER_AREA)\n",
        "                results = holistic.process(frame)  \n",
        "\n",
        "                output = pose_estimation(frame,results)\n",
        "                output =cv2.cvtColor(output,cv2.COLOR_BGR2RGB)\n",
        "#                arr.append(output)\n",
        "                out.write(output)               \n",
        "    else:\n",
        "          for i in range(actualframe):\n",
        "              frame=videodata[i]\n",
        "              frame=cv2.resize(frame,(width,height),interpolation=cv2.INTER_AREA)\n",
        "              results = holistic.process(frame)  \n",
        "              output = pose_estimation(frame,results)\n",
        "              output =cv2.cvtColor(output,cv2.COLOR_BGR2RGB)\n",
        "              out.write(output)\n",
        "          for i in range(45-actualframe):\n",
        "              \n",
        "              newframe=np.zeros(shape=(height,width,3))\n",
        "              \n",
        "\n",
        "              out.write(np.uint8(newframe))\n",
        "    out.release()\n",
        "    print(\"File Created : {}\".format(outpath))\n",
        "    #os.remove(pather)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tXcNFOTd3P3",
        "outputId": "e0d7e223-f49f-4fc4-91d4-68a269eac4d8"
      },
      "source": [
        "for i,j,k in os.walk(\"/content/Tester\"):\n",
        "  for m in k:\n",
        "    pather=os.path.join(\"/content/Tester\",m)\n",
        "    video_array_makeraction(pather)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual frame 93\n",
            "File Created : /content/Tester2/thank you 2.mp4\n",
            "Actual frame 77\n",
            "File Created : /content/Tester2/you.mp4\n",
            "Actual frame 100\n",
            "File Created : /content/Tester2/nothing.mp4\n",
            "Actual frame 73\n",
            "File Created : /content/Tester2/you2.mp4\n",
            "Actual frame 120\n",
            "File Created : /content/Tester2/thank you.mp4\n",
            "Actual frame 102\n",
            "File Created : /content/Tester2/he.mp4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fykLDbToeFZm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9544a10-2c18-4904-fcdb-9cacf6671693"
      },
      "source": [
        "arr=[]\n",
        "for i,j,k in os.walk(\"/content/Tester2\"):\n",
        "\n",
        "  for m in k:\n",
        "    pather=os.path.join(\"/content/Tester2\",m)\n",
        "    print(pather)\n",
        "    a=skvideo.io.vread(pather)\n",
        "    arr.append(a)\n",
        "\n",
        "\n",
        "arr=np.array(arr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Tester2/thank you 2.mp4\n",
            "/content/Tester2/you.mp4\n",
            "/content/Tester2/nothing.mp4\n",
            "/content/Tester2/you2.mp4\n",
            "/content/Tester2/thank you.mp4\n",
            "/content/Tester2/he.mp4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jSZjn5tfZT2",
        "outputId": "ea85b097-e3f1-424f-afde-256a349d0945"
      },
      "source": [
        "arr.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 45, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeTEsHISfclM"
      },
      "source": [
        "prediction=model.predict(arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1rfm5G7fqe_",
        "outputId": "4ac7b434-73aa-4dab-c0e9-96a8c441a9a4"
      },
      "source": [
        "for i in  np.argmax(prediction,axis=1):\n",
        "  print(classes[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "47. they\n",
            "40. I\n",
            "49. How are you\n",
            "41. you\n",
            "49. How are you\n",
            "50. Alright\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxq0V1JCfsTZ",
        "outputId": "96698916-14c1-4ee5-e0c2-1e0a23f991d2"
      },
      "source": [
        "np.argmax(prediction,axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 7, 1, 7, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YruQuM3VfyvY",
        "outputId": "8f04f2f5-173a-494e-dd1a-7cbaaaa6ce21"
      },
      "source": [
        "prediction.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7yG3Hvif-jD",
        "outputId": "9dc8bd87-f45b-4a79-eb9d-db9f31a3a826"
      },
      "source": [
        "prediction[5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
              "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
              "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
              "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0086898e-14],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dvtc4gs3gGx6",
        "outputId": "d6c18710-3b3b-47bc-d309-9943c5f60260"
      },
      "source": [
        "!unzip /content/tester3.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/tester3.zip\n",
            "   creating: tester3/\n",
            "  inflating: tester3/WhatsApp Video 2021-05-01 at 9.21.08 PM (1).mp4  \n",
            "  inflating: tester3/WhatsApp Video 2021-05-01 at 9.21.08 PM.mp4  \n",
            "  inflating: tester3/WhatsApp Video 2021-05-01 at 9.21.09 PM.mp4  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lX3TzJ3XgeZZ"
      },
      "source": [
        "os.makedirs(\"/content/Tester4\")\n",
        "def video_array_makeraction(pather,height=224,width=224):\n",
        "  videodata = skvideo.io.vread(pather)  \n",
        "  outpath=os.path.join(\"/content/Tester4\",os.path.split(pather)[1])\n",
        "  out = cv2.VideoWriter(outpath,cv2.VideoWriter_fourcc('M','J','P','G'), 10, (width,height))\n",
        "  #start=time.time()\n",
        "\n",
        "  with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
        "#    arr=[]\n",
        "    actualframe=len(videodata)\n",
        "    print(\"Actual frame {}\".format(actualframe))\n",
        "    if actualframe >=45:\n",
        "          for i in range (actualframe):\n",
        "            x=round (actualframe/(45)  * i)\n",
        "            if x >=actualframe:\n",
        "                    break\n",
        "            else:\n",
        "                frame =videodata[x]\n",
        "                frame =cv2.resize(frame,(width,height),interpolation=cv2.INTER_AREA)\n",
        "                results = holistic.process(frame)  \n",
        "\n",
        "                output = pose_estimation(frame,results)\n",
        "                output =cv2.cvtColor(output,cv2.COLOR_BGR2RGB)\n",
        "#                arr.append(output)\n",
        "                out.write(output)               \n",
        "    else:\n",
        "          for i in range(actualframe):\n",
        "              frame=videodata[i]\n",
        "              frame=cv2.resize(frame,(width,height),interpolation=cv2.INTER_AREA)\n",
        "              results = holistic.process(frame)  \n",
        "              output = pose_estimation(frame,results)\n",
        "              output =cv2.cvtColor(output,cv2.COLOR_BGR2RGB)\n",
        "              out.write(output)\n",
        "          for i in range(45-actualframe):\n",
        "              \n",
        "              newframe=np.zeros(shape=(height,width,3))\n",
        "              \n",
        "\n",
        "              out.write(np.uint8(newframe))\n",
        "    out.release()\n",
        "    print(\"File Created : {}\".format(outpath))\n",
        "    #os.remove(pather)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6axlQaOpnkF",
        "outputId": "5074feaa-33c5-414c-fd63-ef19af728e5f"
      },
      "source": [
        "for i,j,k in os.walk(\"/content/tester3\"):\n",
        "  for m in k:\n",
        "    pather=os.path.join(\"/content/tester3\",m)\n",
        "    video_array_makeraction(pather)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual frame 101\n",
            "File Created : /content/Tester4/WhatsApp Video 2021-05-01 at 9.21.09 PM.mp4\n",
            "Actual frame 88\n",
            "File Created : /content/Tester4/WhatsApp Video 2021-05-01 at 9.21.08 PM (1).mp4\n",
            "Actual frame 71\n",
            "File Created : /content/Tester4/WhatsApp Video 2021-05-01 at 9.21.08 PM.mp4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGjb3Mkypxr_",
        "outputId": "9f363b26-a0d2-47b5-a9fd-a3a0c7696a48"
      },
      "source": [
        "arr=[]\n",
        "for i,j,k in os.walk(\"/content/Tester4\"):\n",
        "\n",
        "  for m in k:\n",
        "    pather=os.path.join(\"/content/Tester4\",m)\n",
        "    print(pather)\n",
        "    a=skvideo.io.vread(pather)\n",
        "    arr.append(a)\n",
        "\n",
        "\n",
        "arr=np.array(arr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Tester4/WhatsApp Video 2021-05-01 at 9.21.09 PM.mp4\n",
            "/content/Tester4/WhatsApp Video 2021-05-01 at 9.21.08 PM (1).mp4\n",
            "/content/Tester4/WhatsApp Video 2021-05-01 at 9.21.08 PM.mp4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDLqWiYWp48a",
        "outputId": "ad4a818f-cc58-4001-91d3-ec17a6d2dace"
      },
      "source": [
        "prediction=model.predict(arr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7eff52600ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVJ4UjFKp7d4",
        "outputId": "92951c4b-2e6c-4da7-d0d5-9f60d2c42d9f"
      },
      "source": [
        "for i in  np.argmax(prediction,axis=1):\n",
        "  print(classes[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "51. Good Morning\n",
            "40. I\n",
            "40. I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ts3zNl7drQzs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uihQ1Fz1sYZL"
      },
      "source": [
        "## Tring out Bigger Image Size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knSlt67wsGGv"
      },
      "source": [
        "traincheck=np.random.randn(3,45,360,540,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R6I8tqqsURB"
      },
      "source": [
        "mobilenet = tf.keras.applications.InceptionV3(\n",
        "        include_top=False,\n",
        "        input_shape=(360,540,3),\n",
        "        weights='imagenet')\n",
        "    # Keep 9 layers to train\n",
        "trainable = 4\n",
        "for layer in mobilenet.layers[:-trainable]:\n",
        "    layer.trainable = False\n",
        "for layer in mobilenet.layers[-trainable:]:\n",
        "    layer.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IshJSFg1sfzS",
        "outputId": "f24d8db6-03a3-4aac-b783-e295d6c2e13f"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(TimeDistributed(mobilenet ,input_shape=(45,360,540,3)))\n",
        "model.add(TimeDistributed( Flatten()))\n",
        "model.add(LSTM(128, activation='relu', return_sequences=False)) \n",
        "model.add(Dense(64,activation=\"relu\"))\n",
        "model.add(Dense(16,activation=\"softmax\")) \n",
        "model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(), metrics=tf.keras.metrics.Accuracy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA2PtlFqsyoc"
      },
      "source": [
        "model.fit(traincheck,np.array([0,1,0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oc8Ty5Nvs6XM",
        "outputId": "c8fd3beb-711d-464a-c40b-b9387ad72fa4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TP8GZIb7tFoM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}